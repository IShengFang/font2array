{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import skimage.feature\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "#has to do some operations with tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#batch_size\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "class GLCM(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, BATCH_SIZE = 100, d = [1], theta = [0], levels = 256, symmetric = True, normed = True, **kwargs ):\n",
    "        super(GLCM, self).__init__(**kwargs)\n",
    "        self.d = d\n",
    "        self.theta = theta\n",
    "        self.levels = levels\n",
    "        self.symmetric = symmetric\n",
    "        self.normed = normed\n",
    "        self.batch_size = BATCH_SIZE\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "\n",
    "        return (self.batch_size, 4)\n",
    "\n",
    "    def binarization(self, x):\n",
    "        bi_x = K.sign(x)\n",
    "        return bi_x\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        #make input becomes a binarized image\n",
    "        image = self.binarization(inputs)\n",
    "\n",
    "        #calculate GLCM(in a batch shape)\n",
    "        a = image[:, :, :-1, :]\n",
    "        b = image[:, :, 1:, :]\n",
    "\n",
    "        a_or_b = a+b\n",
    "        a_and_b = a*b\n",
    "\n",
    "        one = tf.ones(shape = a.shape)\n",
    "\n",
    "        not_a = one-a\n",
    "        not_b = one-b\n",
    "\n",
    "        # not(a and b)\n",
    "        M0_0 = K.map_fn(K.sum, (one-a_and_b))\n",
    "\n",
    "        # b and (not a)\n",
    "        M0_1 = K.map_fn(K.sum, (b*(not_a)))\n",
    "\n",
    "        # a and (not b)\n",
    "        M1_0 = K.map_fn(K.sum, (a*(not_b)))\n",
    "\n",
    "        # a and b\n",
    "        M1_1 = K.map_fn(K.sum, (a_and_b))\n",
    "\n",
    "\n",
    "        output = tf.stack([M0_0, M0_1, M1_0, M1_1], axis = 1)\n",
    "\n",
    "        \n",
    "        #print(\"output shape: \", output.shape)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (100, 28, 28, 1)          0         \n",
      "_________________________________________________________________\n",
      "glcm_2 (GLCM)                (100, 4)                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 10)                 50        \n",
      "=================================================================\n",
      "Total params: 50\n",
      "Trainable params: 50\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input(batch_shape=(BATCH_SIZE,28, 28, 1))\n",
    "y = GLCM()(x)\n",
    "z = Dense(10, activation='softmax')(y)\n",
    "model = Model(x, z)\n",
    "model.compile(optimizer='Adam', loss=\"MSE\", metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 7s - loss: 0.1741 - acc: 0.1209 - val_loss: 0.1727 - val_acc: 0.1269\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 7s - loss: 0.1726 - acc: 0.1282 - val_loss: 0.1726 - val_acc: 0.1283\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 7s - loss: 0.1716 - acc: 0.1329 - val_loss: 0.1717 - val_acc: 0.1329\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 7s - loss: 0.1704 - acc: 0.1367 - val_loss: 0.1689 - val_acc: 0.1441\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 8s - loss: 0.1680 - acc: 0.1466 - val_loss: 0.1647 - val_acc: 0.1598\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s - loss: 0.1632 - acc: 0.1643 - val_loss: 0.1602 - val_acc: 0.1746\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s - loss: 0.1609 - acc: 0.1682 - val_loss: 0.1602 - val_acc: 0.1759\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s - loss: 0.1598 - acc: 0.1672 - val_loss: 0.1580 - val_acc: 0.1710\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 7s - loss: 0.1586 - acc: 0.1640 - val_loss: 0.1559 - val_acc: 0.1698\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 7s - loss: 0.1525 - acc: 0.1572 - val_loss: 0.1394 - val_acc: 0.1630\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 7s - loss: 0.1309 - acc: 0.1504 - val_loss: 0.1290 - val_acc: 0.1702\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 6s - loss: 0.1295 - acc: 0.1488 - val_loss: 0.1300 - val_acc: 0.1158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f7404a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size= BATCH_SIZE,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
